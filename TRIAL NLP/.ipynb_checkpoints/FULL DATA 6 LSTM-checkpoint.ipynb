{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFuL-RBgXqgU"
   },
   "source": [
    "## Teks Summarisation Using Deep Learning for Analyze Customer Review of Amazon Fine Food Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJDvJ7k4DqNa"
   },
   "source": [
    "### Kelompok\n",
    "Anggota 1 : Muhammad Hussein 201710370311191\n",
    "<br>\n",
    "Anggota 2 : Moch. Chamdani Mustaqim 201710370311285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpWts88MRPUv"
   },
   "source": [
    "# **Permasalahan Yang Kami Angkat**\n",
    "\n",
    "Ulasan dari pelanggan seringkali panjang dan deskriptif. Dengan menganalisis ulasan ini secara manual benar-benar memakan waktu. Di sinilah kelebihan **Pemrosesan Bahasa Alami** dapat diterapkan untuk menghasilkan ringkasan untuk ulasan yang panjang.\n",
    "\n",
    "Kami di sini menggunakan dataset ulasan pelanggan Amazon Fine Food. Tujuan kami adalah untuk menghasilkan ringkasan ulasan pelanggan Amazon Fine Food menggunakan pendekatan berbasis deep learning.\n",
    "\n",
    "<br>\n",
    "\n",
    "# **Custom Attention Layer**\n",
    "\n",
    "Keras tidak secara resmi mendukung Attention Layer. Jadi, kami mengimplementasikan Attention Layer dari github public. Kami mengunduh Attention Layer dari [sini](https://github.com/thushv89/attention_keras/blob/master/layers/attention.py) kemudian menyalin dan menyimpannya di file berbeda bernama attention.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WIujPSa_TwkS"
   },
   "source": [
    "# Mount Google Drive dan Upload file attention.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U9cUYuclPTpC"
   },
   "outputs": [],
   "source": [
    "import attention \n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUValOzcHtEK"
   },
   "source": [
    "# Impor Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2935,
     "status": "ok",
     "timestamp": 1587499127648,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "_Jpu8qLEFxcY",
    "outputId": "c7205673-0e83-47da-f8e9-e9d2e53d68cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UVakjZ3oICgx"
   },
   "source": [
    "# Read dataset\n",
    "\n",
    "Dataset ini terdiri dari ulasan makanan enak dari Amazon. Data ini mencakup periode lebih dari 10 tahun, termasuk semua ~ 500.000 ulasan hingga Oktober 2012. Ulasan ini mencakup produk dan informasi pengguna, peringkat, ulasan teks biasa, dan ringkasan. Ini juga termasuk ulasan dari semua kategori Amazon lainnya.\n",
    "\n",
    "Kami akan mengambil sampel 100.000 ulasan untuk mengurangi waktu pelatihan model kami. Jangan ragu untuk menggunakan seluruh dataset untuk melatih model Anda jika mesin Anda memiliki kekuatan komputasi semacam itu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnK5o4Z1Fxcj"
   },
   "outputs": [],
   "source": [
    "# data=pd.read_csv(path+\"Reviews.csv\",nrows=100000)\n",
    "data=pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGNQKvCaISIn"
   },
   "source": [
    "# Drop Duplicates dan NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cjul88oOFxcr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393565, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)#dropping na\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qi0xD6BkIWAm"
   },
   "source": [
    "# Informasi tentang dataset\n",
    "\n",
    "Mari kita lihat tipe data dan bentuk dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1587499138852,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "__fy-JxTFxc9",
    "outputId": "b201dde8-875d-431d-b514-c75cf475b4fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 393565 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      "Id                        393565 non-null int64\n",
      "ProductId                 393565 non-null object\n",
      "UserId                    393565 non-null object\n",
      "ProfileName               393565 non-null object\n",
      "HelpfulnessNumerator      393565 non-null int64\n",
      "HelpfulnessDenominator    393565 non-null int64\n",
      "Score                     393565 non-null int64\n",
      "Time                      393565 non-null int64\n",
      "Summary                   393565 non-null object\n",
      "Text                      393565 non-null object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 33.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0xLYACiFxdJ"
   },
   "source": [
    "#Preprocessing\n",
    "\n",
    "Melakukan langkah-langkah Preprocessing dasar sangat penting sebelum kami sampai pada bagian pembuatan model. Menggunakan data teks yang tidak beraturan dan tidak bersih adalah langkah yang berpotensi menimbulkan bencana dalam pemrosesan bahasa alami. Jadi pada langkah ini, kami akan membuang semua simbol, karakter, dll yang tidak diinginkan dari teks yang tidak mempengaruhi tujuan masalah yang kami angkat.\n",
    "\n",
    "Berikut ini adalah kamus yang akan kami gunakan untuk memperluas kontraksi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0s6IY-x2FxdL"
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7rvWj-_lVq7q"
   },
   "source": [
    "### **Download stopwords dari library nltk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1312,
     "status": "ok",
     "timestamp": 1587499147978,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "qwi-CnyDKVxB",
    "outputId": "97369fa1-3ac2-48b7-df97-5b3f709e4bfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JFRXFHmI7Mj"
   },
   "source": [
    "Kami akan melakukan sedikit pemrosesan awal untuk data kami:\n",
    "\n",
    "1. Konversikan semuanya menjadi huruf kecil\n",
    "\n",
    "2. Hapus tag HTML\n",
    "\n",
    "3. Pemetaan kontraksi\n",
    "\n",
    "4. Hapus (‘s)\n",
    "\n",
    "5. Hapus teks apa pun di dalam tanda kurung ()\n",
    "\n",
    "6. Hilangkan tanda baca dan karakter khusus\n",
    "\n",
    "7. Hapus stopwords\n",
    "\n",
    "8. Hapus kata-kata pendek\n",
    "\n",
    "berikut fungsi yang kami gunakan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZr-u3OEFxdT"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 # menghapus kata - kata pendek\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2QAeCHWFxdY"
   },
   "outputs": [],
   "source": [
    "#memanggil fungsi\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "snRZY8wjLao2"
   },
   "source": [
    "### **Melihat ulasan 5 pelanggan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 110780,
     "status": "ok",
     "timestamp": 1587499264957,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "NCAIkhWbFxdh",
    "outputId": "cd6500d4-82cd-4e2e-9c82-df8e6f83ed92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsRXocxoFxd-"
   },
   "outputs": [],
   "source": [
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZeD0gs6Lnb-"
   },
   "source": [
    "### **Melihat 10 ringkasan pertama yang telah dilakukan preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176209,
     "status": "ok",
     "timestamp": 1587499342307,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "jQJdZcAzFxee",
    "outputId": "5c05be75-05b7-45dc-801b-2bc04ea8c789"
   },
   "outputs": [],
   "source": [
    "cleaned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1zLpnqsFxey"
   },
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KT_D2cLiLy77"
   },
   "source": [
    "# Drop empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vm8Fk2TCL7Sp"
   },
   "source": [
    "# Memahami distribusi kata dari urutan ulasan\n",
    "\n",
    "Di sini, kami akan menganalisis panjang ulasan dan ringkasan untuk mendapatkan ide keseluruhan tentang distribusi panjang teks. Ini akan membantu kami memperbaiki panjang maksimum urutan ulasan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3708,
     "status": "ok",
     "timestamp": 1587499504991,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "MdF76AHHFxgw",
    "outputId": "9a92033a-2f1f-479f-af7f-da542bb14058"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# mengisi list dengan panjang kalimat\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwdSGIhGMEbz"
   },
   "source": [
    "Kami di sini dapat memperbaiki panjang maksimum ringkasan hingga 8 karena itu tampaknya menjadi panjang ringkasan mayoritas.\n",
    "\n",
    "kami mencoba memahami proporsi panjang ringkasan di bawah 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1780,
     "status": "ok",
     "timestamp": 1587499511276,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "7JRjwdIOFxg3",
    "outputId": "bfb06b64-2cda-4d8a-9bb8-b17a12639055"
   },
   "outputs": [],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=8):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYB4Ga9KMjEu"
   },
   "source": [
    "Kami mengamati bahwa 94% dari ringkasan memiliki panjang di bawah 8. Jadi, kami dapat memperbaiki panjang maksimum ringkasan ke 8.\n",
    "\n",
    "Mari kita perbaiki panjang tinjauan maksimum menjadi 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKD5VOWqFxhC"
   },
   "outputs": [],
   "source": [
    "max_text_len=30\n",
    "max_summary_len=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E6d48E-8M4VO"
   },
   "source": [
    "Selanjutnya kami memilih ulasan dan ringkasan yang panjangnya di bawah atau sama dengan **max_text_len** dan **max_summary_len**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yY0tEJP0FxhI"
   },
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tR1uh8xSNUma"
   },
   "source": [
    "Untuk menambahkan **START** dan **END** token khusus di awal dan akhir ringkasan. Di sini, kami telah memilih **sostok** dan **eostok** sebagai token START dan END\n",
    "\n",
    "Sebelumnya kami memastikan bahwa token khusus yang dipilih tidak pernah muncul dalam ringkasan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwLUH78CFxhg"
   },
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1GlcX4RFOh13"
   },
   "source": [
    "Sebelum kami membangun model, kami perlu membagi dataset kami menjadi set train dan validation. Kami akan menggunakan porsi 90% dari dataset sebagai data train dan 10% yang tersisa sebagai data validation (set holdout):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RakakKHcFxhl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vq1mqyOHOtIl"
   },
   "source": [
    "# Mempersiapkan Tokenizer\n",
    "\n",
    "Tokenizer membangun kosakata dan mengubah urutan kata menjadi urutan bilangan bulat. Membuat tokenizer untuk teks dan ringkasan:\n",
    "\n",
    "# Text Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRHTgX6hFxhq"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#mempersiapkan tokenizer untuk ulasan pada data training\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzvLwYL_PDcx"
   },
   "source": [
    "# Kata - Kata Langka dan Cakupannya\n",
    "\n",
    "Melihat proporsi kata-kata langka dan cakupan totalnya di seluruh teks\n",
    "\n",
    "Di sini, kami mendefinisikan threshold menjadi 4 yang berarti kata yang hitungnya di bawah 4 dianggap sebagai kata yang langka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 987,
     "status": "ok",
     "timestamp": 1587499803916,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "y8KronV2Fxhx",
    "outputId": "162233f1-377f-40d7-a60c-81f01ed980dc"
   },
   "outputs": [],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% kata-kata langka dalam kosa kata:\",(cnt/tot_cnt)*100)\n",
    "print(\"Cakupan total kata-kata langka:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "So-J-5kzQIeO"
   },
   "source": [
    "**Sebagai catatan kami**:\n",
    "\n",
    "\n",
    "* **tot_cnt** memberikan ukuran kosakata (yang berarti setiap kata unik dalam teks)\n",
    " \n",
    "* **cnt** memberi kami no. kata-kata langka yang jumlahnya di bawah ambang batas\n",
    "\n",
    "* **tot_cnt - cnt** memberi kami kata paling umum\n",
    "\n",
    "Selanjutnya kami mendefinisikan tokenizer dengan kata-kata paling umum untuk ulasan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2giEsF3Fxh3"
   },
   "outputs": [],
   "source": [
    "# menyiapkan tokenizer untuk ulasan tentang data pelatihan\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "# ubah urutan teks ke dalam urutan integer\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "# padding nol hingga panjang maksimum\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "# ukuran kosakata (+1 untuk padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8800,
     "status": "ok",
     "timestamp": 1587499830462,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "DCbGMsm4FxiA",
    "outputId": "37561530-d7d5-4b54-af52-14099f0ab223"
   },
   "outputs": [],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQfKP3sqRxi9"
   },
   "source": [
    "# Summary Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRHqyBkBFxiJ"
   },
   "outputs": [],
   "source": [
    "# menyiapkan tokenizer untuk ulasan tentang data training\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KInA6O6ZSkJz"
   },
   "source": [
    "# Kata - Kata Langka dan Cakupannya\n",
    "\n",
    "Mari kita lihat proporsi kata-kata langka dan cakupan totalnya di seluruh ringkasan\n",
    "\n",
    "Di sini, kami mendefinisikan treshold menjadi 6 yang berarti kata yang hitungnya di bawah 6 dianggap sebagai kata yang langka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8147,
     "status": "ok",
     "timestamp": 1587499832931,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "yzE5OiRLFxiM",
    "outputId": "ba29fab3-a600-4927-bda7-cb2b66298b1e"
   },
   "outputs": [],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% kata-kata langka dalam kosa kata:\",(cnt/tot_cnt)*100)\n",
    "print(\"Cakupan total kata-kata langka:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PBhzKuRSw_9"
   },
   "source": [
    "Selanjutnya kami akan mendefinisikan tokenizer dengan kata paling umum untuk ringkasan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fswLvIgFxiR"
   },
   "outputs": [],
   "source": [
    "# menyiapkan tokenizer untuk ulasan tentang data pelatihan\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "# ubah urutan teks ke dalam urutan integer\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "# beri padding nol hingga panjang maksimum\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "# ukuran kosakata\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqwDUT5oTFmn"
   },
   "source": [
    "Kemudian kami memeriksa apakah jumlah token awal kata sama dengan panjang data pelatihan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1634,
     "status": "ok",
     "timestamp": 1587499843122,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "pR8IX9FRFxiY",
    "outputId": "9316c7b2-5109-4d70-a94b-053e6980259f"
   },
   "outputs": [],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVFhFVguTTtw"
   },
   "source": [
    "Di sini, saya menghapus baris yang hanya berisi token **START** dan **END**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZ-vW82sFxih"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cx5NISuMFxik"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOtlDcthFxip"
   },
   "source": [
    "# Membangun model\n",
    "\n",
    "Step paling penting sebelum melakukan training data adalah membangun model berikut kami meringkas sedikit tentang model yang kami gunakan.\n",
    "\n",
    "**Return Sequences = True**: Ketika parameter sequences return diatur ke True, LSTM menghasilkan status hidden dan status sel untuk setiap catatan waktu\n",
    "\n",
    "**Return State = True**: Ketika kondisi pengembalian = True, LSTM menghasilkan status hidden dan status sel dari catatan waktu terakhir saja\n",
    "\n",
    "**Initial State**: Ini digunakan untuk menginisialisasi status internal LSTM untuk catatan waktu pertama\n",
    "\n",
    "**Stacked LSTM**: Tumpukan LSTM memiliki beberapa lapisan LSTM yang saling bertumpuk.\n",
    "\n",
    "Ini mengarah pada representasi urutan yang lebih baik. Kami bisa bereksperimen dengan banyak lapisan LSTM yang ditumpuk satu sama lain.\n",
    "\n",
    "Di sini, kami membangun LSTM 3 susun untuk pembuat encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3556,
     "status": "ok",
     "timestamp": 1587500284287,
     "user": {
      "displayName": "Moch. Chamdani Mustaqim",
      "photoUrl": "https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg",
      "userId": "12782341176521372008"
     },
     "user_tz": -420
    },
    "id": "zXef38nBFxir",
    "outputId": "1874a25a-a984-4cef-f4a1-d17a6b3d142e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      1748900     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 30, 300), (N 721200      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    500000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 30, 300), (N 721200      lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_4[0][0]                     \n",
      "                                                                 lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_5[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 5000)   3005000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 9,281,400\n",
      "Trainable params: 9,281,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output3, state_h3, state_c3= encoder_lstm3(encoder_output2)\n",
    "\n",
    "#encoder lstm 4\n",
    "encoder_lstm4=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output4, state_h4, state_c4= encoder_lstm4(encoder_output3)\n",
    "\n",
    "#encoder lstm 5\n",
    "encoder_lstm5=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm5(encoder_output4)\n",
    "\n",
    "# Membuat decoder, using `encoder_states` sebagai initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Menggabungkan attention input dan decoder output LSTM\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# mendefinisikan model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "new_model = load_model('TUMOR_OTAK_CNN_AUGMENTATION_model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZVlfRuMUcoP"
   },
   "source": [
    "Kami di sini menggunakan `sparse_categorical_crossentropy` sebagai fungsi loss karena fungsi tersebut mengubah urutan integer ke vektor one-hot dengan cepat. Dan menurut literatur hal mengatasi dapat masalah memori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lwfi1Fm8Fxiz"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0ykDbxfUhyw"
   },
   "source": [
    "Konsep `EarlyStopping` kami digunakan untuk menghentikan training jaringan saraf yang kami buat pada waktu yang tepat dengan parameter metrik yang kami tentukan. Di sini kami menggunakan validation loss (val_loss) sebagai parameter `EarlyStopping` yang kami buat. Model kami akan menghentikan proses training setelah validation loss meningkat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-A3J92MUljB"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "# from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mw6CVECaUq5b"
   },
   "source": [
    "Step terakhir adalah training model pada ukuran batch 128 dan memvalidasinya pada set holdout (yang merupakan 10% dari dataset kami):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 189522 samples, validate on 21051 samples\n",
      "Epoch 1/50\n",
      "189522/189522 [==============================] - 329s 2ms/sample - loss: 2.7378 - val_loss: 2.4776\n",
      "Epoch 2/50\n",
      "189522/189522 [==============================] - 320s 2ms/sample - loss: 2.4323 - val_loss: 2.3439\n",
      "Epoch 3/50\n",
      "189522/189522 [==============================] - 318s 2ms/sample - loss: 2.3327 - val_loss: 2.2758\n",
      "Epoch 4/50\n",
      "189522/189522 [==============================] - 318s 2ms/sample - loss: 2.2677 - val_loss: 2.2128\n",
      "Epoch 5/50\n",
      "189522/189522 [==============================] - 319s 2ms/sample - loss: 2.2238 - val_loss: 2.1778\n",
      "Epoch 6/50\n",
      "189522/189522 [==============================] - 318s 2ms/sample - loss: 2.1917 - val_loss: 2.1485\n",
      "Epoch 7/50\n",
      "189522/189522 [==============================] - 318s 2ms/sample - loss: 2.1649 - val_loss: 2.1449\n",
      "Epoch 8/50\n",
      "189522/189522 [==============================] - 317s 2ms/sample - loss: 2.1478 - val_loss: 2.1299\n",
      "Epoch 9/50\n",
      "189522/189522 [==============================] - 316s 2ms/sample - loss: 2.1347 - val_loss: 2.1085\n",
      "Epoch 10/50\n",
      "189522/189522 [==============================] - 318s 2ms/sample - loss: 2.1201 - val_loss: 2.1038\n",
      "Epoch 11/50\n",
      "189522/189522 [==============================] - 318s 2ms/sample - loss: 2.1088 - val_loss: 2.0904\n",
      "Epoch 12/50\n",
      "189522/189522 [==============================] - 318s 2ms/sample - loss: 2.1002 - val_loss: 2.1023\n",
      "Epoch 13/50\n",
      "189522/189522 [==============================] - 318s 2ms/sample - loss: 2.0948 - val_loss: 2.0789\n",
      "Epoch 14/50\n",
      "189522/189522 [==============================] - 318s 2ms/sample - loss: 2.0884 - val_loss: 2.0756\n",
      "Epoch 15/50\n",
      "189522/189522 [==============================] - 318s 2ms/sample - loss: 2.0818 - val_loss: 2.0824\n",
      "Epoch 16/50\n",
      "189522/189522 [==============================] - 318s 2ms/sample - loss: 2.0719 - val_loss: 2.0876\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "history=model.fit([x_tr,y_tr[:,:-1]], \n",
    "                  y_tr.reshape(y_tr.shape[0],\n",
    "                               y_tr.shape[1],\n",
    "                               1)[:,1:] ,\n",
    "                  epochs=50,\n",
    "                  callbacks=[es],\n",
    "                  # verbose=2,\n",
    "                  batch_size=128, \n",
    "                  validation_data=([x_val,y_val[:,:-1]], \n",
    "                                   y_val.reshape(y_val.shape[0],\n",
    "                                                 y_val.shape[1], \n",
    "                                                 1)[:,1:]))\n",
    "stop_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime training model: 5099.11s\n"
     ]
    }
   ],
   "source": [
    "print('Runtime training model: %.2fs' % (stop_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ezKYOp2UxG5"
   },
   "source": [
    "# Memahami plot Diagnostik\n",
    "\n",
    "Sekarang, kami akan memplot beberapa plot diagnostik untuk memahami hasil pembelajaran model dari waktu ke waktu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tDTNLAURFxjE"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSyx-HvpUz2o"
   },
   "source": [
    "Dari plot, kami dapat menyimpulkan bahwa val_loss telah meningkat setelah epoch 17 selama 2 epoch berturut-turut. Karenanya, pelatihan dihentikan pada epoch 19.\n",
    "\n",
    "Selanjutnya, kami membuat kamus untuk mengonversi indeks ke kata untuk kosakata target dan sumber:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBX0zZnOFxjW"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eM_nU_VvFxjq"
   },
   "source": [
    "Siapkan inferensi untuk pembuat enkode dan dekoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9QkrNV-4Fxjt"
   },
   "outputs": [],
   "source": [
    "# Encode urutan input untuk mendapatkan vektor fitur\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Di bawah ini tensor akan menahan state langkah waktu sebelumnya\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Dapatkan embeddings dari urutan decoder\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "\n",
    "# Untuk memprediksi kata berikutnya dalam urutan, \n",
    "# atur status awal ke status dari langkah waktu sebelumnya\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# Lapisan softmax yang padat untuk menghasilkan masalah. atas kosakata target\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOiyk4ToWe74"
   },
   "source": [
    "Kami mendefinisikan fungsi di bawah ini yang merupakan implementasi dari proses inferensi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6f6TTFnBFxj6"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Mengkodekan input sebagai vektor keadaan.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Hasilkan urutan target kosong yang panjangnya 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populasikan kata pertama dari urutan target dengan kata awal.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sampling token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Kondisi Exit: baik mencapai panjang max atau temukan kata berhenti.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Perbarui urutan target (dengan panjang 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Perbarui internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GuDf4TPWt6_"
   },
   "source": [
    "Mendefinisikan fungsi untuk mengubah urutan bilangan bulat menjadi urutan kata untuk ringkasan serta ulasan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAUntznIFxj9"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gM4ALyfWwA9"
   },
   "source": [
    "Berikut adalah beberapa ringkasan yang dihasilkan oleh model yang telah kami buat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUtQmQTmFxkI"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq2text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5e5bcd16073c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Review:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq2text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Original summary:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq2summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted summary:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seq2text' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))    \n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OTkaYNjHW4lC"
   },
   "source": [
    "# **Kesimpulan**\n",
    "\n",
    "Ini hal yang cukup bagus. Meskipun ringkasan aktual dan ringkasan yang dihasilkan oleh model kami tidak cocok dalam hal kata-kata, keduanya menyampaikan makna yang sama. Model kami mampu menghasilkan ringkasan yang dapat dibaca berdasarkan konteks yang ada dalam teks.\n",
    "\n",
    "Ini adalah bagaimana model kami dapat melakukan peringkasan teks menggunakan konsep deep learning dengan Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('NLP_6LSTM_FullData.h5')\n",
    "# model.save_weights('NLP_6LSTM_FullData_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP TUGAS TEKS PROCESSING.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
